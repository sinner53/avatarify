{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avatarify",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinner53/avatarify/blob/master/avatarify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEl-Q4OpsLb9"
      },
      "source": [
        "# Avatarify Colab Server\n",
        "\n",
        "This Colab notebook is for running Avatarify rendering server. It allows you to run Avatarify on your computer **without GPU** in this way:\n",
        "\n",
        "1. When this notebook is executed, it starts listening for incoming requests from your computer;\n",
        "1. You start the client on your computer and it connects to the notebook and starts sending requests;\n",
        "1. This notebooks receives the requests from your computer, renders avatar images and sends them back;\n",
        "\n",
        "To this end, all the heavy work is offloaded from your computer to this notebook so you don't need to have a beafy hardware on your PC anymore.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRpMPl7VyeoD"
      },
      "source": [
        "## Start the server\n",
        "Run the cells below (Shift+Enter) sequentially and pay attention to the hints and instructions included in this notebook.\n",
        "\n",
        "At the end you will get a command for running the client on your computer.\n",
        "\n",
        "## Start the client\n",
        "\n",
        "Make sure you have installed the latest version of Avatarify on your computer. Refer to the [README](https://github.com/alievk/avatarify#install) for the instructions.\n",
        "\n",
        "When it's ready execute this notebook and get the command for running the client on your computer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h0f5WQEjgbH"
      },
      "source": [
        "### Technical details\n",
        "\n",
        "The client on your computer connects to the server via `ngrok` TCP tunnel or a reverse `ssh` tunnel.\n",
        "\n",
        "`ngrok`, while easy to use, can induce a considerable network lag ranging from dozens of milliseconds to a second. This can lead to a poor experience.\n",
        "\n",
        "A more stable connection could be established using a reverse `ssh` tunnel to a host with a public IP, like an AWS `t3.micro` (free) instance. This notebook provides a script for creating a tunnel, but launching an instance in a cloud is on your own (find the manual below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZI4EvKaNUhL"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fYm9X3X125H"
      },
      "source": [
        "### Avatarify\n",
        "Follow the steps below to clone Avatarify and install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC1q-hdat-JP"
      },
      "source": [
        "!cd /content\n",
        "!rm -rf *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE4_YSbsiX_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ca000f-9241-4f45-e675-2ea603315858"
      },
      "source": [
        "!git clone https://github.com/sinner53/avatarify.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'avatarify'...\n",
            "remote: Enumerating objects: 1456, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 1456 (delta 5), reused 0 (delta 0), pack-reused 1443 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1456/1456), 6.04 MiB | 9.44 MiB/s, done.\n",
            "Resolving deltas: 100% (921/921), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8fTBhOEUM_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b83896b-3c18-49e3-f237-46171dc12e5c"
      },
      "source": [
        "cd avatarify"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/avatarify\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FONInDgZUmcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce93387-a9a9-4795-9cda-d891ec3fe78a"
      },
      "source": [
        "!git clone https://github.com/alievk/first-order-model.git fomm\n",
        "!pip install face-alignment==1.0.0 msgpack_numpy pyyaml==6.0.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fomm'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Total 211 (delta 0), reused 0 (delta 0), pack-reused 211 (from 1)\u001b[K\n",
            "Receiving objects: 100% (211/211), 58.16 MiB | 28.84 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n",
            "Collecting face-alignment==1.0.0\n",
            "  Downloading face_alignment-1.0.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting msgpack_numpy\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pyyaml==6.0.1\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.0.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.0.0) (0.25.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.0.0) (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from msgpack_numpy) (1.1.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.0.0) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.0.0) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.0.0) (2025.1.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.0.0) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.0.0) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.0.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.0.0) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.0.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.0.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->face-alignment==1.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->face-alignment==1.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->face-alignment==1.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->face-alignment==1.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->face-alignment==1.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->face-alignment==1.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->face-alignment==1.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->face-alignment==1.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->face-alignment==1.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.0.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->face-alignment==1.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->face-alignment==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->face-alignment==1.0.0) (3.0.2)\n",
            "Downloading face_alignment-1.0.0-py2.py3-none-any.whl (22 kB)\n",
            "Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m854.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyyaml, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgpack_numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, face-alignment\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed face-alignment-1.0.0 msgpack_numpy-0.4.8 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyyaml-6.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPgXoqE_gAyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b3a1a8-a56d-49bf-ce6c-acb9a0ed01b4"
      },
      "source": [
        "!scripts/download_data.sh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  228M  100  228M    0     0   106M      0  0:00:02  0:00:02 --:--:--  106M\n",
            "Expected checksum: 8a45a24037871c045fbb8a6a8aa95ebc\n",
            "Found checksum:    8a45a24037871c045fbb8a6a8aa95ebc  vox-adv-cpk.pth.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1soT4zEEFzp"
      },
      "source": [
        "### ngrok\n",
        "Follow the steps below to setup ngrok. You will also need to sign up on the ngrok site and get your authtoken (free).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbptNwHL1s61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5083fadf-cdcf-4f5d-cdc5-48a2e0369916"
      },
      "source": [
        "# Download ngrok\n",
        "!scripts/get_ngrok.sh"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok is not found, installing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qk1FCeeaviZ"
      },
      "source": [
        "# Run\n",
        "Start here if the runtime was restarted after installation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f2iYcQVI2ss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f18750-71ae-494d-ea94-5d5330bb9dde"
      },
      "source": [
        "cd /content/avatarify"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/avatarify\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxK_ZZjPz_Rr"
      },
      "source": [
        "#!git pull origin"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA-h22jF6-ks"
      },
      "source": [
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "import json\n",
        "import time\n",
        "\n",
        "\n",
        "def run_with_pipe(command):\n",
        "  commands = list(map(shlex.split,command.split(\"|\")))\n",
        "  ps = Popen(commands[0], stdout=PIPE, stderr=PIPE)\n",
        "  for command in commands[1:]:\n",
        "    ps = Popen(command, stdin=ps.stdout, stdout=PIPE, stderr=PIPE)\n",
        "  return ps.stdout.readlines()\n",
        "\n",
        "\n",
        "def get_tunnel_adresses():\n",
        "  info = run_with_pipe(\"curl http://localhost:4040/api/tunnels\")\n",
        "  assert info\n",
        "\n",
        "  info = json.loads(info[0])\n",
        "  for tunnel in info['tunnels']:\n",
        "    url = tunnel['public_url']\n",
        "    port = url.split(':')[-1]\n",
        "    local_port = tunnel['config']['addr'].split(':')[-1]\n",
        "    print(f'{url} -> {local_port} [{tunnel[\"name\"]}]')\n",
        "    if tunnel['name'] == 'input':\n",
        "      in_addr = url\n",
        "    elif tunnel['name'] == 'output':\n",
        "      out_addr = url\n",
        "    else:\n",
        "      print(f'unknown tunnel: {tunnel[\"name\"]}')\n",
        "\n",
        "  return in_addr, out_addr"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfHa02CBWoNN"
      },
      "source": [
        "# Input and output ports for communication\n",
        "local_in_port = 5557\n",
        "local_out_port = 5558"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcULGnhGJJjC"
      },
      "source": [
        "# Start the worker\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PnArK75mRqx"
      },
      "source": [
        "# (Re)Start the worker\n",
        "with open('/tmp/run.txt', 'w') as f:\n",
        "  ps = Popen(\n",
        "      shlex.split(f'./run.sh --is-worker --in-port {local_in_port} --out-port {local_out_port} --no-vcam --no-conda'),\n",
        "      stdout=f, stderr=f)\n",
        "  time.sleep(3)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfUqQxMtRSvc"
      },
      "source": [
        "This command should print lines if the worker is successfully started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0eY8gkBqUJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458347a0-ac19-4dde-eace-6dd95883d36a"
      },
      "source": [
        "!ps aux | grep 'python3 afy/cam_fomm.py' | grep -v grep | tee /tmp/ps_run\n",
        "!if [[ $(cat /tmp/ps_run | wc -l) == \"0\" ]]; then echo \"Worker failed to start\"; cat /tmp/run.txt; else echo \"Worker started\"; fi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        1146 28.6  1.1 3462924 150816 ?      Rl   16:02   0:00 python3 afy/cam_fomm.py --config \n",
            "Worker started\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz9gpLD0IsCL"
      },
      "source": [
        "# Open ngrok tunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyB7XIxL0XpD"
      },
      "source": [
        "#### Get ngrok token\n",
        "Go to https://dashboard.ngrok.com/auth/your-authtoken (sign up if required), copy your authtoken and put it below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDtPpi77AkQ1"
      },
      "source": [
        "# Paste your authtoken here in quotes\n",
        "authtoken = \"2tBYCNSwgbGHtg6g7aYY6QFN9GE_3ukJJJFxa2tdxd9NafVzM\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gASaDrsFXLXA"
      },
      "source": [
        "Set your region\n",
        "\n",
        "Code | Region\n",
        "--- | ---\n",
        "us | United States\n",
        "eu | Europe\n",
        "ap | Asia/Pacific\n",
        "au | Australia\n",
        "sa | South America\n",
        "jp | Japan\n",
        "in | India"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5e9VR9NYckJ"
      },
      "source": [
        "# Set your region here in quotes\n",
        "region = \"eu\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ5_PE_EHpCg"
      },
      "source": [
        "config =\\\n",
        "f\"\"\"\n",
        "version: 2\n",
        "authtoken: {authtoken}\n",
        "region: {region}\n",
        "console_ui: False\n",
        "tunnels:\n",
        "  input:\n",
        "    addr: {local_in_port}\n",
        "    proto: tcp\n",
        "  output:\n",
        "    addr: {local_out_port}\n",
        "    proto: tcp\n",
        "\"\"\"\n",
        "\n",
        "with open('ngrok.conf', 'w') as f:\n",
        "  f.write(config)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z49OEhAdDI7Y"
      },
      "source": [
        "# (Re)Open tunnel\n",
        "ps = Popen('./scripts/open_tunnel_ngrok.sh', stdout=PIPE, stderr=PIPE)\n",
        "time.sleep(3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAyPH2t2C64H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0218559e-f7e0-4284-f9ae-6d5f4a9872f3"
      },
      "source": [
        "# Get tunnel addresses\n",
        "try:\n",
        "  in_addr, out_addr = get_tunnel_adresses()\n",
        "  print(\"Tunnel opened\")\n",
        "except Exception as e:\n",
        "  [print(l.decode(), end='') for l in ps.stdout.readlines()]\n",
        "  print(\"Something went wrong, reopen the tunnel\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcp://0.tcp.eu.ngrok.io:14032 -> 5557 [input]\n",
            "tcp://6.tcp.eu.ngrok.io:18742 -> 5558 [output]\n",
            "Tunnel opened\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc6rg2HQAocK"
      },
      "source": [
        "### [Optional] AWS proxy\n",
        "Alternatively you can create a ssh reverse tunnel to an AWS `t3.micro` instance (it's free). It has lower latency than ngrok.\n",
        "\n",
        "1. In your AWS console go to Services -> EC2 -> Instances -> Launch Instance;\n",
        "1. Choose `Ubuntu Server 18.04 LTS` AMI;\n",
        "1. Choose `t3.micro` instance type and press Review and launch;\n",
        "1. Confirm your key pair and press Launch instances;\n",
        "1. Go to the security group of this instance and edit inbound rules. Add TCP ports 5557 and 5558 and set Source to Anywhere. Press Save rules;\n",
        "1. ssh into the instance (you can find the command in the Instances if you click on the Connect button) and add this line in the end of `/etc/ssh/sshd_config`:\n",
        "```\n",
        "GatewayPorts yes\n",
        "```\n",
        "then restart `sshd`\n",
        "```\n",
        "sudo service sshd restart\n",
        "```\n",
        "1. Copy your `key_pair.pem` by dragging and dropping it into avatarify folder in this notebook;\n",
        "1. Use the command below to open the tunnel;\n",
        "1. Start client with a command (substitute `run_mac.sh` with `run_windows.bat` or `run.sh`)\n",
        "```\n",
        "./run_mac.sh --is-client --in-addr tcp://instace.compute.amazonaws.com:5557 --out-addr tcp://instance.compute.amazonaws.com:5558\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdN5Qj2BCYsr"
      },
      "source": [
        "# Open reverse ssh tunnel (uncomment line below)\n",
        "# !./scripts/open_tunnel_ssh.sh key_pair.pem ubuntu@instance.compute.amazonaws.com"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccZ24BT4Jdis"
      },
      "source": [
        "# Start the client\n",
        "When you run the cell below it will print a command. Run this command on your computer:\n",
        "\n",
        "1. Open a terminal (in Windows open `Anaconda Prompt`);\n",
        "2. Change working directory to the `avatarify` directory:</br>\n",
        "* Windows (change `C:\\path\\to\\avatarify` to your path)</br>\n",
        "`cd C:\\path\\to\\avatarify`</br></br>\n",
        "* Mac/Linux (change `/path/to/avatarify` to your path)</br>\n",
        "`cd /path/to/avatarify`\n",
        "3. Copy-paste to the terminal the command below and run;\n",
        "4. It can take some time to connect (usually up to 10 seconds). If the preview window doesn't appear in a minute or two, look for the errors above in this notebook and report in the [issues](https://github.com/alievk/avatarify/issues) or [Slack](https://join.slack.com/t/avatarify/shared_invite/zt-dyoqy8tc-~4U2ObQ6WoxuwSaWKKVOgg)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gaqS0mZWF1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90358df7-936c-498d-96f4-97722ad3718b"
      },
      "source": [
        "print('Copy-paste to the terminal the command below and run (press Enter)\\n')\n",
        "print('Mac:')\n",
        "print(f'./run_mac.sh --is-client --in-addr {in_addr} --out-addr {out_addr}')\n",
        "print('\\nWindows:')\n",
        "print(f'run_windows.bat --is-client --in-addr {in_addr} --out-addr {out_addr}')\n",
        "print('\\nLinux:')\n",
        "print(f'./run.sh --is-client --in-addr {in_addr} --out-addr {out_addr}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy-paste to the terminal the command below and run (press Enter)\n",
            "\n",
            "Mac:\n",
            "./run_mac.sh --is-client --in-addr tcp://0.tcp.eu.ngrok.io:14032 --out-addr tcp://6.tcp.eu.ngrok.io:18742\n",
            "\n",
            "Windows:\n",
            "run_windows.bat --is-client --in-addr tcp://0.tcp.eu.ngrok.io:14032 --out-addr tcp://6.tcp.eu.ngrok.io:18742\n",
            "\n",
            "Linux:\n",
            "./run.sh --is-client --in-addr tcp://0.tcp.eu.ngrok.io:14032 --out-addr tcp://6.tcp.eu.ngrok.io:18742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3h92xQ9KA-R"
      },
      "source": [
        "# Logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvodbjapKBQi"
      },
      "source": [
        "If something doesn't work as expected, please run the cells below and include the logs in your report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GeT7KxON0Ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "aead464b-0349-448f-8259-ab44ee967202"
      },
      "source": [
        "#@title\n",
        "!cat ./var/log/cam_fomm.log | head -100"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1740067338.031398] Loading Predictor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1FQcdzwqdce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "3b8a418f-1197-43c1-ecf5-ce4d6f4e180a"
      },
      "source": [
        "#@title\n",
        "!cat ./var/log/recv_worker.log | tail -100"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: ./var/log/recv_worker.log: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YThWBXCf_yzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "a88b6076-dbfc-4218-be79-dd40151c2209"
      },
      "source": [
        "#@title\n",
        "!cat ./var/log/predictor_worker.log | tail -100"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: ./var/log/predictor_worker.log: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhJzygCP_6p3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "88092381-f7ac-48dd-a178-38bf7c313f7b"
      },
      "source": [
        "#@title\n",
        "!cat ./var/log/send_worker.log | tail -100"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: ./var/log/send_worker.log: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrzNffhR_8HQ"
      },
      "source": [],
      "execution_count": 23,
      "outputs": []
    }
  ]
}